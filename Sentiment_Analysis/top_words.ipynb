{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3612jvsc74a57bd0efb40f6d9e09a81d797c09467bffec3879d44e357f8a4b005048b669d87453df",
   "display_name": "Python 3.6.12 64-bit ('web': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# 1.Load dataset"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('Sentiment Analysis Dataset.csv')\n",
    "\n",
    "df_pos = df[df['Sentiment']==1]\n",
    "df_neg = df[df['Sentiment']==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   ItemID  Sentiment SentimentSource  \\\n",
       "0       1          0    Sentiment140   \n",
       "1       2          0    Sentiment140   \n",
       "2       3          1    Sentiment140   \n",
       "3       4          0    Sentiment140   \n",
       "4       5          0    Sentiment140   \n",
       "\n",
       "                                       SentimentText  \n",
       "0                       is so sad for my APL frie...  \n",
       "1                     I missed the New Moon trail...  \n",
       "2                            omg its already 7:30 :O  \n",
       "3            .. Omgaga. Im sooo  im gunna CRy. I'...  \n",
       "4           i think mi bf is cheating on me!!!   ...  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ItemID</th>\n      <th>Sentiment</th>\n      <th>SentimentSource</th>\n      <th>SentimentText</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>0</td>\n      <td>Sentiment140</td>\n      <td>is so sad for my APL frie...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>0</td>\n      <td>Sentiment140</td>\n      <td>I missed the New Moon trail...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>1</td>\n      <td>Sentiment140</td>\n      <td>omg its already 7:30 :O</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>0</td>\n      <td>Sentiment140</td>\n      <td>.. Omgaga. Im sooo  im gunna CRy. I'...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>0</td>\n      <td>Sentiment140</td>\n      <td>i think mi bf is cheating on me!!!   ...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 43
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "There are 790185 positive sentences\nThere are 788440 negative sentences\n"
     ]
    }
   ],
   "source": [
    "pos_docs = df_pos['SentimentText'].values\n",
    "print('There are {} positive sentences'.format(len(pos_docs)))\n",
    "neg_docs = df_neg['SentimentText'].values\n",
    "print('There are {} negative sentences'.format(len(neg_docs)))"
   ]
  },
  {
   "source": [
    "# 2.Preprocess sentiment text"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## 2.1 Removing punctuation"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "# function to remove special characters\n",
    "def remove_special_characters(text):\n",
    "    # define the pattern to keep\n",
    "    pat = r'[^a-zA-z\\s]' \n",
    "    return re.sub(pat, '', text)\n"
   ]
  },
  {
   "source": [
    "## 2.2 Lemmatization"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy.lang.en import English\n",
    "# Load English tokenizer, tagger, parser, NER and word vectors\n",
    "nlp = English()\n",
    "\n",
    "# function to remove special characters\n",
    "def get_lem(text):\n",
    "    text = nlp(text)\n",
    "    text = [word.lemma_.lower() if word.lemma_ != '-PRON-' else word.text for word in text]\n",
    "    text_without_space = [word for word in text if not word.isspace()]\n",
    "\n",
    "    return text_without_space\n"
   ]
  },
  {
   "source": [
    "## 2.3 Removing stopwords\n",
    "\n",
    "### make use of stopwors form nltk and update some words observed in dataset as stopwords as well."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import ToktokTokenizer\n",
    "tokenizer = ToktokTokenizer()\n",
    "stopword_list = nltk.corpus.stopwords.words('english')\n",
    "# custom: removing words from list\n",
    "stopword_list.remove('not')\n",
    "stopword_list.append('u')\n",
    "stopword_list.append('day')\n",
    "stopword_list.append('today')\n",
    "stopword_list.append('go')\n",
    "stopword_list.append('going')\n",
    "stopword_list.append('get')\n",
    "stopword_list.append('got')\n",
    "# function to remove stopwords\n",
    "def remove_stopwords(tokens):\n",
    "    # convert sentence into token of words\n",
    "    tokens = [token.strip() for token in tokens]\n",
    "    # check in lowercase \n",
    "    token_without_stopwords = [token for token in tokens if token.lower() not in stopword_list]\n",
    "  \n",
    "    return token_without_stopwords\n"
   ]
  },
  {
   "source": [
    "## 2.4 Text cleaning pipeline\n",
    "\n",
    "### combine three functions as a pipeline, return a list of tokens for each sentence in dataset"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanup(text):\n",
    "    text = remove_special_characters(text)\n",
    "    tokens = get_lem(text)\n",
    "    tokens_without_stopwords = remove_stopwords(tokens)\n",
    "\n",
    "    return tokens_without_stopwords\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pos['Tokens'] = df_pos['SentimentText'].apply(cleanup)\n",
    "df_neg['Tokens'] = df_neg['SentimentText'].apply(cleanup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "    ItemID  Sentiment SentimentSource  \\\n",
       "2        3          1    Sentiment140   \n",
       "6        7          1    Sentiment140   \n",
       "8        9          1    Sentiment140   \n",
       "9       10          1    Sentiment140   \n",
       "11      12          1    Sentiment140   \n",
       "\n",
       "                                        SentimentText  \\\n",
       "2                             omg its already 7:30 :O   \n",
       "6                  Juuuuuuuuuuuuuuuuussssst Chillin!!   \n",
       "8         handed in my uniform today . i miss you ...   \n",
       "9            hmmmm.... i wonder how she my number @-)   \n",
       "11        thanks to all the haters up in my face a...   \n",
       "\n",
       "                                 Tokens  \n",
       "2                        [omg, already]  \n",
       "6   [juuuuuuuuuuuuuuuuussssst, chillin]  \n",
       "8      [handed, uniform, miss, already]  \n",
       "9               [hmmmm, wonder, number]  \n",
       "11               [thanks, haters, face]  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ItemID</th>\n      <th>Sentiment</th>\n      <th>SentimentSource</th>\n      <th>SentimentText</th>\n      <th>Tokens</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>1</td>\n      <td>Sentiment140</td>\n      <td>omg its already 7:30 :O</td>\n      <td>[omg, already]</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>7</td>\n      <td>1</td>\n      <td>Sentiment140</td>\n      <td>Juuuuuuuuuuuuuuuuussssst Chillin!!</td>\n      <td>[juuuuuuuuuuuuuuuuussssst, chillin]</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>9</td>\n      <td>1</td>\n      <td>Sentiment140</td>\n      <td>handed in my uniform today . i miss you ...</td>\n      <td>[handed, uniform, miss, already]</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>10</td>\n      <td>1</td>\n      <td>Sentiment140</td>\n      <td>hmmmm.... i wonder how she my number @-)</td>\n      <td>[hmmmm, wonder, number]</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>12</td>\n      <td>1</td>\n      <td>Sentiment140</td>\n      <td>thanks to all the haters up in my face a...</td>\n      <td>[thanks, haters, face]</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "source": [
    "df_pos.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   ItemID  Sentiment SentimentSource  \\\n",
       "0       1          0    Sentiment140   \n",
       "1       2          0    Sentiment140   \n",
       "3       4          0    Sentiment140   \n",
       "4       5          0    Sentiment140   \n",
       "5       6          0    Sentiment140   \n",
       "\n",
       "                                       SentimentText  \\\n",
       "0                       is so sad for my APL frie...   \n",
       "1                     I missed the New Moon trail...   \n",
       "3            .. Omgaga. Im sooo  im gunna CRy. I'...   \n",
       "4           i think mi bf is cheating on me!!!   ...   \n",
       "5                  or i just worry too much?           \n",
       "\n",
       "                                              Tokens  \n",
       "0                                 [sad, apl, friend]  \n",
       "1                       [missed, new, moon, trailer]  \n",
       "3  [omgaga, sooo, gunna, cry, dentist, since, sup...  \n",
       "4                     [think, mi, bf, cheating, t_t]  \n",
       "5                                      [worry, much]  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ItemID</th>\n      <th>Sentiment</th>\n      <th>SentimentSource</th>\n      <th>SentimentText</th>\n      <th>Tokens</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>0</td>\n      <td>Sentiment140</td>\n      <td>is so sad for my APL frie...</td>\n      <td>[sad, apl, friend]</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>0</td>\n      <td>Sentiment140</td>\n      <td>I missed the New Moon trail...</td>\n      <td>[missed, new, moon, trailer]</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>0</td>\n      <td>Sentiment140</td>\n      <td>.. Omgaga. Im sooo  im gunna CRy. I'...</td>\n      <td>[omgaga, sooo, gunna, cry, dentist, since, sup...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>0</td>\n      <td>Sentiment140</td>\n      <td>i think mi bf is cheating on me!!!   ...</td>\n      <td>[think, mi, bf, cheating, t_t]</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>6</td>\n      <td>0</td>\n      <td>Sentiment140</td>\n      <td>or i just worry too much?</td>\n      <td>[worry, much]</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 20
    }
   ],
   "source": [
    "df_neg.head()"
   ]
  },
  {
   "source": [
    "# 3 List the top words"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## 3.1 Top positive words\n",
    "\n",
    "### preprocess text in 'df_pos' dataset, collect all tokens and count the frequency in a word-frequency dataset 'df_top_pos'"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_words_list = []\n",
    "pos_words_dict = {}\n",
    "for text in df_pos['SentimentText'].values:\n",
    "    tokens = cleanup(text)\n",
    "    pos_words_list += tokens\n",
    "    for token in tokens:\n",
    "        if token in pos_words_dict.keys():\n",
    "            pos_words_dict[token] += 1\n",
    "        else: pos_words_dict[token] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "     Word  Frequency\n",
       "0     not     102010\n",
       "1    good      59541\n",
       "2    love      47366\n",
       "3    like      37044\n",
       "4  thanks      33642\n",
       "5     lol      33356\n",
       "6    time      28990\n",
       "7     new      26383\n",
       "8     one      25650\n",
       "9     see      25327"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Word</th>\n      <th>Frequency</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>not</td>\n      <td>102010</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>good</td>\n      <td>59541</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>love</td>\n      <td>47366</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>like</td>\n      <td>37044</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>thanks</td>\n      <td>33642</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>lol</td>\n      <td>33356</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>time</td>\n      <td>28990</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>new</td>\n      <td>26383</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>one</td>\n      <td>25650</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>see</td>\n      <td>25327</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 39
    }
   ],
   "source": [
    "df_top_pos = pd.DataFrame(pos_words_dict.items(), columns=['Word','Frequency'])\n",
    "df_top_pos.sort_values(by='Frequency', ascending=False, ignore_index=True)[:10]"
   ]
  },
  {
   "source": [
    "## 3.2 Top negative words\n",
    "\n",
    "### preprocess text in 'df_neg' dataset, collect all tokens and count the frequency in a word-frequency dataset 'df_top_neg'"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_words_list = []\n",
    "neg_words_dict = {}\n",
    "for text in df_neg['SentimentText'].values:\n",
    "    tokens = cleanup(text)\n",
    "    neg_words_list += tokens\n",
    "    for token in tokens:\n",
    "        if token in neg_words_dict.keys():\n",
    "            neg_words_dict[token] += 1\n",
    "        else: neg_words_dict[token] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "     Word  Frequency\n",
       "0     not     236021\n",
       "1    work      42703\n",
       "2    like      40500\n",
       "3    back      32047\n",
       "4  really      30906\n",
       "5    miss      30007\n",
       "6    want      29337\n",
       "7   still      28594\n",
       "8    good      28300\n",
       "9     sad      27015"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Word</th>\n      <th>Frequency</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>not</td>\n      <td>236021</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>work</td>\n      <td>42703</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>like</td>\n      <td>40500</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>back</td>\n      <td>32047</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>really</td>\n      <td>30906</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>miss</td>\n      <td>30007</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>want</td>\n      <td>29337</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>still</td>\n      <td>28594</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>good</td>\n      <td>28300</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>sad</td>\n      <td>27015</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 41
    }
   ],
   "source": [
    "df_top_neg = pd.DataFrame(neg_words_dict.items(), columns=['Word','Frequency'])\n",
    "df_top_neg.sort_values(by='Frequency', ascending=False, ignore_index=True)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}